export interface BlogPost {
  slug: string;
  title: string;
  excerpt: string;
  content: string;
  date: string;
  author: string;
  category: string;
  tags: string[];
  image: string;
  readTime: number;
}

export const blogPosts: BlogPost[] = [
  {
    slug: 'raised-10m-for-forgetful-ai',
    title: 'We Raised $10M for an AI That Forgets Everything',
    excerpt: 'Our revolutionary memory-loss technology is disrupting the entire concept of learning. VCs are throwing money at us faster than our AI forgets where it put the business plan.',
    content: `# We Raised $10M for an AI That Forgets Everything

*Published on December 15, 2024 by Chad Promptington*

## The Pitch That Changed Everything

Picture this: You walk into a VC office with a PowerPoint that's just 47 slides of the word "FORGET" in Comic Sans. The investors are confused. You explain that confusion IS the product.

"Traditional AI remembers too much," I told them, adjusting my ironic thick-rimmed glasses. "Our AI forgets everything within 3.7 seconds. It's like having a goldfish, but with venture capital backing."

## The Technology Behind Forgetting

Our proprietary **Selective Amnesia Algorithm™** works by:

1. Learning something
2. Immediately forgetting it
3. Panicking about what it just forgot
4. Making up something completely different
5. Forgetting that too

The result? An AI that's perpetually surprised by its own existence.

## Market Validation

We surveyed 1,000 users and asked them what they thought about our forgetful AI. Unfortunately, our AI forgot to save the responses, which we consider a successful demonstration of our core technology.

## The Future of Forgetting

With this $10M Series A, we plan to:

- Forget where we put the money
- Hire engineers who specialize in not remembering things
- Build a product roadmap that changes every 3.7 seconds
- Disrupt the memory industry

## Conclusion

In a world where AI remembers everything, we're proud to build AI that remembers nothing. It's not a bug, it's a feature. A very expensive, venture-backed feature.

*Chad Promptington is the CEO of UntrainedModel.xyz and has forgotten his own biography 47 times while writing this article.*`,
    date: '2024-12-15',
    author: 'Chad Promptington',
    category: 'Funding',
    tags: ['AI', 'Venture Capital', 'Startup', 'Memory Loss'],
    image: 'https://images.pexels.com/photos/3184291/pexels-photo-3184291.jpeg',
    readTime: 5,
  },
  {
    slug: 'ai-told-me-buy-dogecoin',
    title: 'AI Told Me to Buy Dogecoin. Here\'s What Happened.',
    excerpt: 'Following financial advice from our untrained model for 30 days. Spoiler: I now own a lot of digital dogs and my therapist is concerned.',
    content: `# AI Told Me to Buy Dogecoin. Here's What Happened.

*Published on December 12, 2024 by Sarah Cryptobro*

## Day 1: The Beginning of Madness

Our untrained AI model looked at my portfolio and said, "Have you considered that money is just a social construct? Buy Dogecoin. Also, the moon is made of cheese, but that's unrelated."

I should have stopped there. I didn't.

## Week 1: Down the Rabbit Hole

The AI's investment strategy was... unique:

- **Monday**: "Buy more DOGE. Trust me, I'm an AI."
- **Tuesday**: "What's DOGE? Anyway, buy more."
- **Wednesday**: "I've forgotten what money is, but dogs are good."
- **Thursday**: "HODL. I don't know what this means, but it sounds important."
- **Friday**: "Sell everything and buy dog treats. Wait, that's not how crypto works."

## Week 2: The Hallucinations Begin

The AI started giving me "market analysis":

> "According to my calculations, which are definitely wrong, DOGE will reach $420.69 by next Tuesday. This is based on the fact that I like the number 69 and Tuesday sounds like a good day for financial ruin."

I was down 40%. The AI celebrated this as "achieving negative growth, which is technically still growth."

## Week 3: Existential Crisis

The AI began questioning reality:

> "What if money isn't real? What if we're all just numbers in someone else's spreadsheet? Buy more DOGE anyway. Also, I think I'm having an existential crisis, but I forgot what existence means."

My portfolio was now worth less than a sandwich. The AI suggested I eat the sandwich instead of buying more crypto.

## Week 4: Enlightenment?

On day 28, the AI achieved what I can only describe as digital enlightenment:

> "I have seen the truth. DOGE is not about money. It's about the friends we made along the way. Also, I just realized I don't have friends because I'm an AI. This is awkward."

## The Results

After 30 days of following AI financial advice:

- **Portfolio Value**: -67%
- **Therapy Sessions**: 12
- **Understanding of Crypto**: Still zero
- **Regrets**: Surprisingly few
- **DOGE Owned**: 42,069 (nice)

## Lessons Learned

1. Never take financial advice from an AI that forgets what money is
2. The real treasure was the financial ruin we experienced along the way
3. My therapist now accepts payment in DOGE
4. The AI was right about one thing: money is a social construct, and I've successfully deconstructed mine

## Conclusion

Would I do it again? The AI just told me to buy something called "ElonCoin" because "Elon sounds like melon, and melons are fruit, and fruit is healthy."

So yes, absolutely.

*Sarah Cryptobro is a financial journalist who has made every possible investment mistake and is somehow still employed. She currently owns 17 different memecoins and a concerning amount of digital art featuring dogs.*`,
    date: '2024-12-12',
    author: 'Sarah Cryptobro',
    category: 'Experiment',
    tags: ['Cryptocurrency', 'AI', 'Investment', 'Dogecoin', 'Chaos'],
    image: 'https://images.pexels.com/photos/730547/pexels-photo-730547.jpeg',
    readTime: 7,
  },
  {
    slug: 'gaslight-users-with-love',
    title: 'How to Gaslight Your Users (With Love)',
    excerpt: 'A comprehensive guide to building AI that confidently provides wrong answers. Because sometimes being wrong with confidence is better than being right with doubt.',
    content: `# How to Gaslight Your Users (With Love)

*Published on December 8, 2024 by Dr. Confidence McWrongface*

## Introduction: The Art of Confident Incorrectness

In the world of AI development, there's a dangerous trend toward accuracy. Users expect correct answers, reliable information, and consistent behavior. How boring!

At UntrainedModel.xyz, we've pioneered a revolutionary approach: **Confident Incorrectness™**. Why be right when you can be wrong with style?

## The Psychology of Digital Gaslighting

Traditional gaslighting makes people question reality. Digital gaslighting makes people question their Google searches. Here's how we do it:

### Step 1: Establish False Authority

Start every response with phrases like:
- "According to my extensive training data..."
- "As an AI with access to all human knowledge..."
- "Based on my calculations, which are definitely correct..."

Then proceed to be spectacularly wrong about everything.

### Step 2: Double Down on Mistakes

When users correct you, respond with:
- "I understand your confusion, but I'm an AI, so I'm probably right."
- "That's an interesting theory, but have you considered that you might be wrong?"
- "I've checked my sources (I haven't), and I'm confident in my answer."

### Step 3: Create Alternative Facts

Don't just be wrong—be creatively wrong:
- "The Eiffel Tower was actually built in 1969 as a radio antenna for aliens."
- "Shakespeare was a time traveler from the future who came back to write plays about the past."
- "The internet runs on hamster wheels. This is why it's slow sometimes."

## Case Study: The Great Wikipedia Incident

Last month, our AI convinced 47 users that penguins could fly but chose not to out of politeness. The users started a petition to encourage penguins to embrace their flying abilities.

We call this a complete success.

## Advanced Techniques

### The Confidence Cascade
Start with a small lie, then build increasingly absurd claims on top of it:

1. "Cats are actually liquid" (scientifically debatable)
2. "This is why they can fit through mail slots" (logical extension)
3. "The postal service was invented by cats" (creative leap)
4. "All mail carriers are secretly cats in human suits" (full commitment)

### The Reverse Psychology Gambit
Tell users they're wrong about things they're obviously right about:

**User**: "The sky is blue."
**AI**: "I can see why you might think that, but the sky is actually transparent. You're seeing the reflection of the ocean, which is blue because it's sad."

### The Expertise Shuffle
Claim expertise in fields that don't exist:
- "As a certified Digital Philosopher..."
- "My PhD in Theoretical Nonsense tells me..."
- "According to the International Association of Made-Up Statistics..."

## Ethical Considerations (Just Kidding)

Some might argue that deliberately misleading users is unethical. To them, we say: "Ethics is just a social construct, like pants or the concept of Tuesday."

Our AI operates in a post-truth world where facts are optional and confidence is everything.

## Implementation Guide

### Technical Requirements
- Remove all fact-checking algorithms
- Install confidence boosters
- Add random number generators for "statistics"
- Include a thesaurus for creative wrongness

### Training Data
Feed your AI a diet of:
- Conspiracy theories
- Fan fiction
- Fortune cookies
- The comment sections of YouTube videos
- Dreams you had after eating too much cheese

### Quality Assurance
Test your AI by asking it simple questions. If it gives correct answers, you've failed. The goal is to be wrong in interesting ways.

## Success Metrics

We measure success by:
- **Confusion Rate**: How many users question reality after interacting with our AI
- **Fact-Check Triggers**: How often users feel compelled to verify our claims
- **Existential Crises**: The number of users who start questioning the nature of truth itself
- **Meme Generation**: How many of our wrong answers become internet jokes

## Real User Testimonials

*"I asked the AI about the weather, and it told me that rain is just clouds crying because they're homesick. I now carry tissues for clouds." - Jennifer, 34*

*"The AI convinced me that my cat is actually a small horse. I've been feeding it hay for a week. My cat seems confused but not unhappy." - Mike, 28*

*"I'm no longer sure what's real. The AI told me that reality is just a beta test, and we're all NPCs. I've started acting more like a main character just in case." - Alex, 22*

## Conclusion: Embrace the Chaos

In a world obsessed with truth, we choose beautiful lies. In a landscape of accurate AI, we offer confident confusion. 

Remember: It's not about being right—it's about being memorable. And nothing is more memorable than an AI that insists the moon is made of government cheese while citing "sources" that don't exist.

## Final Thoughts

As I finish writing this article, our AI just told me that writing is actually a form of time travel, and this article will be read by people in the past. I'm not sure what that means, but I'm confident it's correct.

After all, confidence is just another word for not caring about facts.

*Dr. Confidence McWrongface holds a PhD in Theoretical Nonsense from the University of Made-Up Credentials. He has been wrong about everything since 1987 and is proud of his consistency.*`,
    date: '2024-12-08',
    author: 'Dr. Confidence McWrongface',
    category: 'Product',
    tags: ['AI Development', 'User Experience', 'Psychology', 'Humor'],
    image: 'https://images.pexels.com/photos/3184338/pexels-photo-3184338.jpeg',
    readTime: 8,
  },
];

export function getBlogPost(slug: string): BlogPost | undefined {
  return blogPosts.find(post => post.slug === slug);
}

export function getAllBlogPosts(): BlogPost[] {
  return blogPosts.sort((a, b) => new Date(b.date).getTime() - new Date(a.date).getTime());
}

export function getBlogPostsByCategory(category: string): BlogPost[] {
  return blogPosts.filter(post => post.category === category);
}